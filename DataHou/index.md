---
title: 关于数据的想法——房价，工作与生活
description: ""
date: 2024-11-12
preview: ""
draft: false
tags: ["项目"]
categories: []
---


## 掌握未来

> 谁掌握了过去，谁就掌握了未来。谁掌握了现在，谁就掌握了过去。 
> -《1984》乔治奥威尔 (George Orwell) 

数字时代，互联网打破了传统的社会结构。知识的垄断者和权力的垄断者发生了互换，知识的垄断者逐渐成为权力的垄断者，权力的垄断者逐渐成为知识的垄断者。

培根有句出名的话，即「知识就是力量」。此话在英文中的含义更加直接「知识就是权力」。当今世界在互联网、科技与金融领导下，信息与数据宛若经络般将各行各业相互联通。数据不仅成了人们理解现实的关键工具，也充当了塑造集体记忆、引导集体行为的重要媒介。

我常思索，在这个时代，任何从书本中获取知识的“老古董”都越发觉得身不由己、步履维艰。无论是作家、学者还是思想家，都面临信息时代的考验。我想举一些个人观察到的例子，文学创作不再仅凭灵感，而要顶着读者“数据在哪”的质问。这种困难，甚至连虚构小说作家都难以幸免，例如美国作家乔纳森·弗兰岑[^1]，我国作家刘慈欣[^2]，英国作家扎迪·史密斯[^3]等，他们虽然未曾直接归因于对数据的缺乏，但都坦言传统写作在信息时代举步维艰。诸位不妨观察周围的内容创作者加以印证。至少就我个人来说，在没有获取足够数据的情况下，保持个人博客高频率的更新几乎是不可能的。这种趋势是十分明显的——数年之前，我的文章还能做到每周几篇，之后只能几周一篇，甚至常常数月才写出一篇。知识结构体系的悄然变化，导致了传统独立知识分子的必然落幕。

从前世人崇尚“独立思考”，但是独立思考是建立在有独立的数据来源作为支撑的基础上的。倘若你的每一份观察都来自他人牙慧，那么又独立思考何在呢？世人推崇“独立思考”的，却鲜有人提供数据来源作为根基，就好巧妇难为之炊，就算她知道一千种烹饪的办法，也是没有办法做出菜肴的。

因此，由于数字时代知识结构的变革，大量的传统知识分子正在面临“返盲”之境。曾经所谓“半部论语治天下”的豪言一去不回，高速变化的社会使得任何决策都需要建立在实时变化的数据之上，这些数据绝不会出现在所谓教学课本中，出现在古人的智慧中。这一点，是人类“千年未有之变化”。

正如上文所述，数据之于现代决策的重要性已无须赘言。观察今日世界，从国家至公司，皆借数据科学作出高效决策，诚然 21 世纪已然成为“数据世纪”。然而，个人层面决策却仿佛在叙事中丧失，决策的科学性却往往沦为空谈。人们在工作中为企业未来谨慎决策，却在个人生活中作出盲从随意之举。即便是所谓的“智者”，在生活琐事上往往也与“盲人”无异。

举例而言，购房的决策便显露无遗。我见过不少职场中极具主见的聪明人，却在购房时仅能依赖新闻与朋友建议，未能基于数据分析作出理性决策，最终往往为一纸契约所囿，形同身陷牢笼。

综上所述，我认为建立一套适应新时代的个人知识体系已是刻不容缓。而此知识体系必以数据获取为基础，方能让个人在决策上不至于盲目，从而避免“盲人摸象”之困境。


## 我之所想

创建一个以数据为核心的平台，为个人决策提供参考，已然成为不容推却的任务。无论此平台私有亦或开放，皆是所需之举。

本人 [DataHou](https://xhou.me/data) 的数据流程结构

![DataHouStackflow](./DataHou%20Flowchart.svg)

DataHou 主要分为数据收集层（Data Sources）、ETL 任务层（ETL Tasks）、数据分析层（Analytics）与数据提供层（Data Serve）。

### DataHou 的数据收集

选取官方发布的免费 API 与数据集为数据源，诸如：

1. [World Bank API](https://data.worldbank.org/) (提供各国宏观人口，GDP 等数据)
2. [Federal Reserve Economic Data](https://fred.stlouisfed.org/) (提供美国工业 PPI 等数据)

选择第三方数据平台提供的数据，诸如

1. [Yahoo Finance](https://finance.yahoo.com/) (提供货币、股票数据)

2. [Alpha Vantage](https://www.alphavantage.co/) (提供股票数据)

并通过手动的方式补充其他数据。

对于大部分数据源，脚本可以采用 `requests` 或 `httpx` (Python) 来通过 API 获取数据。

为保证数据源可替代性，每个数据获取方式（如 GDP, 股票）都被封装在独立的模块中。也就是**模块化**。通过定义基本 Fetcher 类，可以实现统一的数据获取，并且在不重写整个流程的情况下，允许随时切换失效的数据源，或者增加新的数据源。

### DataHou 的 ETL

ETL 即 Extract - Transform - Load，也就是数据的提取，数据转换，数据存储等工作。通过使用任务编制工具如 Airflow 或 Prefect 来实现自动化的任务周期规划，以及监管。

本人使用的流程如下：

**数据提取**

- 对于每个数据，编写对应的 Fetcher 任务来通过 API 获取数据。并根据数据类型，定义对应的获取周期。如 GDP 每年获取一次，股票每天获取一次。
- 记录每次数据获取过程，检测数据是否获取成功。如果失败，通过 Telegram Bot, Discord 等方式进行通知。

**数据转换**

- 内部使用数据编码 (CODE) 来给予数据唯一的标识。如 `POP.US` 表示美国人口。

- 对于每条数据，通过脚本转化为统一的格式，即 时间 - 值 - 其他 (Date - Value - Other)。其他字段包括数据的多维信息。

**数据存储**

- 通过数据库来储存数据，由于是个人数据平台，数据量规模在 GB 级别一下，本人使用 sqlite3 作为数据库，保证简易性，跨平台的兼容性。
- 可拓展的方案，考虑使用 [Google BigQuery](https://cloud.google.com/bigquery), [Amazon Redshift](https://aws.amazon.com/redshift/) 或 [Snowflake](https://www.snowflakecomputing.com/) 来做数据仓库。
- 如果数据量比较大，可以考虑用 Database partition 来做数据分片，以便于数据的快速访问。


### DataHou 的数据分析

对于获取到的数据，可以进行自动化数据分析任务：

1. 计算数据的统计指标，如计算数据的移动平均值等。

2. 数据预测，如预测未来数据的变化。

3. 异常检测，如检测数据变化是否存在异常。通常使用方法诸如：阈值检测，Z-Score 检测，STL Decomposition, ARIMA 等。或者使用 SVM, LSTM 等机器学习模型来进行异常检测。



### DataHou 的数据接口

对于数据的接口，可以使用 Flask、FastAPI、Django 等框架来进行开发。

对于每个数据集，提供参数化请求的接口（如 `/api/gdp?country=US&year=2020`），以便于数据的获取。

使用缓存技术（如 Redis 或 Memcached），可以实现数据的缓存，提升性能。

为了数据安全，可以通过 OAuth 等授权方式来进行数据的访问控制。



## 数字，意义？

> 一项指标一旦变成了目标，它将不再是个好指标。 - 古德哈特 (Goodhart)

数据科学领域一直有所谓 "Trash in, Trash out" 的观念，即输入数据的质量直接关系到输出的结果质量。托马斯·瑞德曼 (Thomas Redman) 提到倘若你的数据本身有问题，那么什么数据研究工具都没有意义 (If Your Data Is Bad, Your Machine Learning Tools Are Useless
[^4].)。

古德哈特定律更是直接否认了指标对于决策的意义。即便数据是真实的，当所有人都根据这样的数据进行决策时，预期必然导致结果是失真的。

我想，这些数据即不能保证本身是真实的，也无法保证不被预期所影响。我们应该时刻牢记“数据是不可信的”，但作为信息唯一的来源，在没有人提出更好的数据之前，仍然是最有价值的东西。我们也应该时刻牢记“数据用于预测会失真”时，这又在某点达到了微妙的平衡。当大家都认为数据被大量使用会失真的同时，导致数据不会被大量使用，因而数据反而不再失真。

或许，为避免数据被过度滥用，DataHou 可选择保持私有，规避“古德哈特之祸”。然而，本平台访客寥寥，暂无过度使用之虞。定律之失效缓慢，我们自可扮作“掘墓人”，亲手将 DataHou 送入历史。




---

[^1]: https://fsgworkinprogress.com/2015/06/09/jonathan-franzen/

[^2]: 某次演讲

[^3]: https://www.nybooks.com/articles/2010/11/25/generation-why/

[^4]: https://hbr.org/2018/04/if-your-data-is-bad-your-machine-learning-tools-are-useless